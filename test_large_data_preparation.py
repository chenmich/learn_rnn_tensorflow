# Copyright 2017 The Chenmich Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
''' Test large-data-preparation module
'''
import unittest
import json
import csv
import numpy as np
from fs import memoryfs
import large_data_preparation as ldp

#for all test class
def get_fsys():
    ''' simulate the file system with pyfilesystem
        pyfilesystem implement the general interface of file system.
        Replace the built-in file system with pyfilesystem to improve
        dependence injection
    '''
    model_data_fs = memoryfs.MemoryFS()
    model_data_fs.makedir('data')
    model_data_fs.makedir('data/raw_data')
    model_data_fs.makedir('data/result_data')
    _raw_data = np.arange(20000).reshape(4000, 5).tolist()
    filenames = ['some00000.csv', 'some00001.csv', 'some00002.csv',
                 'some00003.csv', 'some00004.csv']

    for _file in filenames:
        with model_data_fs.open('data/raw_data/' + _file, mode='w') as csvfile:
            writer = csv.writer(csvfile)
            for line in _raw_data:
                writer.writerow(line)
    return model_data_fs
#

class test_make_example(unittest.TestCase):
    ''' Test _make_example function in the large_data_preparation module
    '''
    def test_examples(self):
        ''' Test the examples generated by function _make_examples
        '''
        lines = np.arange(20000).reshape(4000, 5)
        sequence_length = 200
        length = len(lines)
        examples = ldp._make_examples(200, lines[sequence_length:])
        _num_example = len(lines[sequence_length:]) // (2*sequence_length) + 1
        length = len(examples)
        self.assertEqual(length, 2*_num_example)
        _tmp = examples[2*(_num_example - 1)]
        self.assertEqual(len(_tmp), sequence_length // 2)
        self.assertEqual(len(examples[2*_num_example - 1]), sequence_length //2)

#
class test_combinate_examples(unittest.TestCase):
    ''' test combinate the group of examples into list
    '''
    def test_combinate_examples(self):
        ''' valid two list are combinated into one list
        '''
        examples = np.arange(10000).reshape(2000, 5).tolist()
        _examples = np.arange(2000).reshape(400, 5).tolist()
        #test result of combination
        _length = len(examples)
        _other_length = len(_examples)
        ldp._combinate_example(examples, _examples)
        total_length = len(examples)
        self.assertEqual(total_length, _length + _other_length)
        #test parameter
        with self.assertRaises(ValueError):
            ldp._combinate_example(examples, 2)
            ldp._combinate_example(3, _examples)
            ldp._combinate_example(3.0, 2.0)

#
class test_get_file_list(unittest.TestCase):
    ''' test the _get_file_list with memoryfs
    '''
    def setUp(self):
        self._fsys = get_fsys()

    def test_result(self):
        path = 'data/raw_data/'
        _extension = '*.csv'
        files = ldp._get_file_list(self._fsys, path, _extension)
        length = len(list(files))
        self.assertGreater(length, 0)
#
class test_save_examples(unittest.TestCase):
    ''' test _save_example function with pyfilesystem
    '''
    def setUp(self):
        ''' built file system with memoryfs
        '''
        self._fsys = get_fsys()
    def test_train_dataset(self):
        pass
#
class test_prediction_sequence(unittest.TestCase):
    ''' test function _get_prediction_sequence with memoryfs
    '''
    def setUp(self):
        self._fsys = get_fsys()
    def test_get_prediction_sequence(self):
        ''' test _get_prediction-sequence function with memoryfs
        '''
        files = ldp._get_file_list(self._fsys, 'data/raw_data/', '*.csv')
        sequence_length = 200
        key = None
        sequence = None
        filename = files[0]
        with self._fsys.open('data/raw_data/' + filename, mode='r') as seq_file:
            reader = csv.reader(seq_file)
            _sequence = []
            for _line in reader:
                _sequence.append(_line)

            key, sequence = ldp._get_prediction_sequence(filename,
                                                         sequence_length,
                                                         _sequence)

            self.assertEqual(key, filename.split('.')[0])
            self.assertEqual(len(sequence), sequence_length)
    def test_save_prediction_sequence(self):
        ''' test _save_prediction_sequence function with memoryfs
        '''
        sequence_length = 200
        feature_size = 5
        _prediction_sequence = {"some000000":np.arange(sequence_length*feature_size)
                                             .reshape(sequence_length, feature_size).tolist(),
                                "some000001":np.arange(sequence_length*feature_size,
                                                       2*sequence_length*feature_size)
                                             .reshape(sequence_length, feature_size).tolist()}
        _tmp_fsys = self._fsys.opendir('data')
        ldp._save_prediction_sequence(_tmp_fsys, _prediction_sequence)
        _tmp_fsys.close()
        with self._fsys.open('data/result_data/' + 'prediction_sequence.json',
                             mode='r') as jsonfile:
            _pr_seq = json.load(jsonfile)
        self.assertEqual(len(_pr_seq['some000000']), 200)
        self.assertEqual(len(_pr_seq['some000001']), 200)


if __name__ == "__main__":
    unittest.main()
