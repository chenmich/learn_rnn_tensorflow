# Copyright 2017 The Chenmich Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
''' Test large-data-preparation module
'''
import unittest
import json
import csv
import numpy as np
from fs import memoryfs
import large_data_preparation as ldp

#for all test class
def get_fsys():
    ''' simulate the file system with pyfilesystem
        pyfilesystem implement the general interface of file system.
        Replace the built-in file system with pyfilesystem to improve
        dependence injection
    '''
    model_data_fs = memoryfs.MemoryFS()
    model_data_fs.makedir('data')
    model_data_fs.makedir('data/raw_data')
    model_data_fs.makedir('data/result_data')
    _raw_data = np.arange(20000).reshape(4000, 5).tolist()
    filenames = ['some00000.csv', 'some00001.csv', 'some00002.csv',
                 'some00003.csv', 'some00004.csv']

    for _file in filenames:
        with model_data_fs.open('data/raw_data/' + _file, mode='w') as csvfile:
            writer = csv.writer(csvfile)
            for line in _raw_data:
                writer.writerow(line)
    return model_data_fs.opendir('data')

#
ldp.SEQUENCE_LENGTH = 200
ldp.FEATURE_SIZE = 5
ldp.MODEL_DATA_FS = get_fsys()
#
class test_make_example(unittest.TestCase):
    ''' Test _make_example function in the large_data_preparation module
    '''
    def test_examples(self):
        ''' Test the examples generated by function _make_examples
        '''
        lines = np.arange(20000).reshape(4000, 5)
        length = len(lines)
        examples = ldp._make_examples(lines[ldp.SEQUENCE_LENGTH:])
        _num_example = len(lines[ldp.SEQUENCE_LENGTH:]) // (2*ldp.SEQUENCE_LENGTH) + 1
        length = len(examples)
        self.assertEqual(length, 2*_num_example)
        _tmp = examples[2*(_num_example - 1)]
        self.assertEqual(len(_tmp), ldp.SEQUENCE_LENGTH // 2)
        self.assertEqual(len(examples[2*_num_example - 1]), ldp.SEQUENCE_LENGTH //2)

#
class test_combinate_examples(unittest.TestCase):
    ''' test combinate the group of examples into list
    '''
    def test_combinate_examples(self):
        ''' valid two list are combinated into one list
        '''
        _length_ = 400
        examples = np.arange(ldp.SEQUENCE_LENGTH
                             *ldp.FEATURE_SIZE).reshape(ldp.SEQUENCE_LENGTH,
                                                        ldp.FEATURE_SIZE).tolist()
        _examples = np.arange(_length_*
                              ldp.FEATURE_SIZE).reshape(_length_,
                                                        ldp.FEATURE_SIZE).tolist()
        #test result of combination
        _length = len(examples)
        _other_length = len(_examples)
        ldp._combinate_example(examples, _examples)
        total_length = len(examples)
        self.assertEqual(total_length, _length + _other_length)
        #test parameter
        with self.assertRaises(ValueError):
            ldp._combinate_example(examples, 2)
            ldp._combinate_example(3, _examples)
            ldp._combinate_example(3.0, 2.0)

#
class test_get_file_list(unittest.TestCase):
    ''' test the _get_file_list with memoryfs
    '''
    def setUp(self):
        self._fsys = get_fsys()
    def tearDown(self):
        self._fsys.close()

    def test_result(self):
        ''' Test gotten file list
        '''
        path = 'raw_data/'
        _extension = '*.csv'
        files = ldp._get_file_list(path, _extension)
        length = len(list(files))
        self.assertGreater(length, 0)
#
class test_save_examples(unittest.TestCase):
    ''' test _save_example function with pyfilesystem
    '''
    def setUp(self):
        ''' built file system with memoryfs
        '''
        self._fsys = get_fsys()
    def tearDown(self):
        self._fsys.close()
    def test_train_dataset(self):
        ''' Test save train data
        '''
        raise ValueError("un-complemented!")
#
class test_prediction_sequence(unittest.TestCase):
    ''' test function _get_prediction_sequence with memoryfs
    '''
    def setUp(self):
        self._fsys = get_fsys()
    def tearDown(self):
        self._fsys.close()
    def test_get_prediction_sequence(self):
        ''' test _get_prediction-sequence function with memoryfs
        '''
        files = ldp._get_file_list('raw_data/', '*.csv')
        key = None
        sequence = None
        filename = files[0]
        with ldp.MODEL_DATA_FS.open('/raw_data/' + filename, mode='r') as seq_file:
            reader = csv.reader(seq_file)
            _sequence = []
            for _line in reader:
                _sequence.append(_line)

            key, sequence = ldp._get_prediction_sequence(filename, _sequence)
            self.assertEqual(key, filename.split('.')[0])
            self.assertEqual(len(sequence), ldp.SEQUENCE_LENGTH)
    def test_save_prediction_sequence(self):
        ''' test _save_prediction_sequence function with memoryfs
        '''
        #preparation for test
        sequence_length = 200
        feature_size = 5
        _prediction_sequence = {"some000000":np.arange(sequence_length*feature_size)
                                             .reshape(sequence_length, feature_size).tolist(),
                                "some000001":np.arange(sequence_length*feature_size,
                                                       2*sequence_length*feature_size)
                                             .reshape(sequence_length, feature_size).tolist()}
        #execute
        ldp._save_prediction_sequence(_prediction_sequence)
        #examination
        with ldp.MODEL_DATA_FS.open('result_data/' + 'prediction_sequence.json',
                             mode='r') as jsonfile:
            _pr_seq = json.load(jsonfile)
        self.assertEqual(len(_pr_seq['some000000']), ldp.SEQUENCE_LENGTH)
        self.assertEqual(len(_pr_seq['some000001']), ldp.SEQUENCE_LENGTH)


if __name__ == "__main__":
    unittest.main()
